{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e9dcfd",
   "metadata": {},
   "source": [
    "# Deepfaceë¥¼ ì´ìš©í•´ ì •í™•ë„ ë†’ì€ ì–¼êµ´ ì¸ì‹ í”„ë¡œê·¸ë¨ ë§Œë“¤ê¸°\n",
    "https://github.com/serengil/deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1876bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/deepface/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-05 13:35:37.210256: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-05 13:35:37.210612: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-05 13:35:37.257323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-05 13:35:39.744141: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-05 13:35:39.744611: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbff83b",
   "metadata": {},
   "source": [
    "ìœ ì‚¬ë„ë¥¼ %ë¡œ í‘œí˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6954b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_distance_to_similarity(distance,threshold,verified):\n",
    "    if verified:\n",
    "        # ì¼ì¹˜í•  ê²½ìš°\n",
    "        ratio=max(0,1-(distance/threshold))\n",
    "        return round(90+ratio*10,2)\n",
    "    else:\n",
    "        #ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "        ratio = max(0,1-(distance/(threshold*2)))\n",
    "        return round(ratio*60,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead19ab",
   "metadata": {},
   "source": [
    "# ì–¼êµ´ ìœ ì‚¬ë„ ë¹„êµ í•¨ìˆ˜(ArcFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image1,image2):\n",
    "    #ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬\n",
    "    if image1 is None or image2 is None:\n",
    "        return \"ì´ë¯¸ì§€ë¥¼ ë‘ ì¥ ëª¨ë‘ ì—…ë¡œë“œ í•˜ì„¸ìš”.\"\n",
    "    img1=cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.cvtColor(image2,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(\"face1.jpg\",img1)\n",
    "    cv2.imwrite(\"face2.jpg\",img2)\n",
    "    \n",
    "    try:\n",
    "        threshold=0.68 #ArcFace ê¸°ì¤€ ë‘ ì´ë¯¸ì§€ê°€ ì¼ì¹˜í•˜ëŠ” ê¸°ì¤€\n",
    "        result=DeepFace.verify('face1.jpg','face2.jpg',model_name=\"ArcFace\",enforce_detection=True)\n",
    "        distance=result['distance']\n",
    "        verified=result['verified']\n",
    "        similarity_score=convert_distance_to_similarity(distance,threshold,verified)\n",
    "        result_text=f\"ArcFace ê¸°ì¤€ ì–¼êµ´ ìœ ì‚¬ë„ ë¶„ì„: \\nìœ ì‚¬ë„: {similarity_score:.2f}%\\nì–¼êµ´ ì¼ì¹˜ì—¬ë¶€: {'ì¼ì¹˜' if verified else 'ë¶ˆì¼ì¹˜'}\"\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        return f\"ì˜¤ë¥˜: {str(e)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c5724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"ì–¼êµ´ ìœ ì‚¬ë„ ë¹„êµ\")\n",
    "    with gr.Tab(\"image Upload\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image1=gr.Image(label=\"first_image\")\n",
    "            with gr.Column():\n",
    "                image2=gr.Image(label=\"second_image\")\n",
    "    output = gr.Textbox(label=\"ì–¼êµ´ ìœ ì‚¬ë„: \",lines=5)\n",
    "    convert_btn=gr.Button(\"ìœ ì‚¬ë„ ë¹„êµí•˜ê¸°\")\n",
    "    convert_btn.click(\n",
    "        fn=image_to_text,inputs=[image1,image2],outputs=output)\n",
    "app.launch(inline=False,share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ce0846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654bb86",
   "metadata": {},
   "source": [
    "# ì—¬ëŸ¬ ëª¨ë¸ê³¼ ìœ ì‚¬ë„ ì¸¡ì • ì¸¡ë„ë¥¼ ë³€ê²½í•˜ë©´ì„œ ìœ ì‚¬ë„ ë¹„êµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e745f",
   "metadata": {},
   "source": [
    "* ëª¨ë¸ ëª©ë¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19296b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['Facenet512','ArcFace','SFace','Facenet','GhostFaceNet','VGG_Face','OpenFace','DeepID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365da18",
   "metadata": {},
   "source": [
    "* ëª¨ë¸ë³„ ì¶”ì²œ metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9d093f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Facenet512': 'euclidean_l2',\n",
       " 'ArcFace': 'cosine',\n",
       " 'SFace': 'cosine',\n",
       " 'Facenet': 'euclidean_l2',\n",
       " 'GhostFaceNet': 'cosine',\n",
       " 'VGG_Face': 'euclidean',\n",
       " 'OpenFace': 'euclidean_l2',\n",
       " 'DeepID': 'euclidian'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_metric=dict(Facenet512='euclidean_l2',ArcFace='cosine',\n",
    "                        SFace='cosine',Facenet='euclidean_l2',GhostFaceNet='cosine',\n",
    "                        VGG_Face='euclidean',OpenFace='euclidean_l2',DeepID='euclidian')\n",
    "recommended_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0eaf3",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ë³„ threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8362545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ArcFace': 0.68,\n",
       " 'Facenet512': 0.3,\n",
       " 'SFace': 0.593,\n",
       " 'Facenet': 0.4,\n",
       " 'GhostFaceNet': 0.25,\n",
       " 'VGG_Face': 0.4,\n",
       " 'OpenFace': 0.55,\n",
       " 'DeepID': 0.17}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_threshold=dict(ArcFace=0.68,Facenet512=0.3,\n",
    "                        SFace=0.593,Facenet=0.4,GhostFaceNet=0.25,\n",
    "                        VGG_Face=0.4,OpenFace=0.55,DeepID=0.17)\n",
    "model_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f938f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text2(image1,image2,model):\n",
    "    #ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬\n",
    "    if image1 is None or image2 is None:\n",
    "        return \"ì´ë¯¸ì§€ë¥¼ ë‘ ì¥ ëª¨ë‘ ì—…ë¡œë“œ í•˜ì„¸ìš”.\"\n",
    "    img1=cv2.cvtColor(image1,cv2.COLOR_BGR2RGB)\n",
    "    img2=cv2.cvtColor(image2,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # ì¶”ì²œ metric / threshold\n",
    "    metric = recommended_metric.get(model,'cosine')\n",
    "    threshold=model_threshold.get(model,0.5)\n",
    "    try:\n",
    "        result=DeepFace.verify(img1,img2,model_name=model,distance_metric=metric,\n",
    "                               detector_backend=\"opencv\",\n",
    "                               enforce_detection=True)\n",
    "        distance=result['distance']\n",
    "        verified=result['verified']\n",
    "        similarity_score=convert_distance_to_similarity(distance,threshold,verified)\n",
    "        result_text=(f\"ArcFace ê¸°ì¤€ ì–¼êµ´ ìœ ì‚¬ë„ ë¶„ì„:\\n\"\n",
    "                     f\"ê±°ë¦¬({metric}):{distance:4f}\\n\"\n",
    "                     f\" \\nìœ ì‚¬ë„: {similarity_score:.2f}%\\n\"\n",
    "                     f\"ì–¼êµ´ ì¼ì¹˜ì—¬ë¶€: {'ì¼ì¹˜' if verified else 'ë¶ˆì¼ì¹˜'}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        return f\"ì˜¤ë¥˜: {str(e)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5faf18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-12-05 13:56:32 - ğŸ”— facenet512_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5 to /home/user/.deepface/weights/facenet512_weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5\n",
      "To: /home/user/.deepface/weights/facenet512_weights.h5\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95.0M/95.0M [00:05<00:00, 16.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-12-05 13:56:47 - ğŸ”— deepid_keras_weights.h5 will be downloaded from https://github.com/serengil/deepface_models/releases/download/v1.0/deepid_keras_weights.h5 to /home/user/.deepface/weights/deepid_keras_weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/deepid_keras_weights.h5\n",
      "To: /home/user/.deepface/weights/deepid_keras_weights.h5\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.61M/1.61M [00:00<00:00, 25.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"ì–¼êµ´ ìœ ì‚¬ë„ ë¹„êµ\")\n",
    "    with gr.Tab(\"image Upload\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                image1=gr.Image(label=\"first_image\")\n",
    "            with gr.Column():\n",
    "                image2=gr.Image(label=\"second_image\")\n",
    "        model=gr.Dropdown(\n",
    "            label=\"ëª¨ë¸ì„ íƒ\",\n",
    "            choices=models,\n",
    "            value=\"ArcFace\")\n",
    "    output = gr.Textbox(label=\"ì–¼êµ´ ìœ ì‚¬ë„: \",lines=10)\n",
    "    convert_btn=gr.Button(\"ìœ ì‚¬ë„ ë¹„êµí•˜ê¸°\")\n",
    "    convert_btn.click(\n",
    "        fn=image_to_text2,inputs=[image1,image2,model],outputs=output)\n",
    "app.launch(inline=False,share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbec28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
